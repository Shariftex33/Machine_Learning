import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline

# Generate a synthetic dataset with some noise
np.random.seed(0)
X = np.sort(5 * np.random.rand(80, 1), axis=0)
y = np.sin(X).ravel() + np.random.randn(80) * 0.1

# Create models with different polynomial degrees
degrees = [1, 4, 15]
models = []

for degree in degrees:
    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
    model.fit(X, y)
    models.append(model)

plt.figure(figsize=(14, 4))

for i, degree in enumerate(degrees):
    ax = plt.subplot(1, len(degrees), i + 1)
    plt.setp(ax, xticks=(), yticks=())

    # Predict on a finely spaced grid of X values
    X_test = np.linspace(0, 5, 1000)[:, np.newaxis]
    y_pred = models[i].predict(X_test)

    plt.scatter(X, y, s=20, label="Training data")
    plt.plot(X_test, y_pred, color='r', label="Model")

    if degree == 1:
        plt.title("Degree %d (Underfitting)" % degree)
    elif degree == 4:
        plt.title("Degree %d (Good Fit)" % degree)
    elif degree == 15:
        plt.title("Degree %d (Overfitting)" % degree)

plt.show()
